#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# Copyright (C) Red Hat, Inc
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.

from dci_analytics import dci_db
from dci.analytics import access_data_layer as a_d_l
from dci_analytics import elasticsearch as es
from dci_analytics.synchronizers import jobs

from kombu import Connection, Exchange, Queue
from kombu.mixins import ConsumerMixin
import requests


_INDEX = "jobs"

rabbit_url = "amqp://guest:guest@rabbitmq:5672//"


def push(job, update=False):
    _id = job["id"]
    doc = es.get(_INDEX, _id)
    if not doc:
        es.push(_INDEX, job, _id)
        return job
    if update:
        es.put(_INDEX, job, _id)
        return job
    return None


class Worker(ConsumerMixin):
    def __init__(self, connection, queues, session):
        self.connection = connection
        self.queues = queues
        self.session_db = session

    def get_consumers(self, Consumer, channel):
        return [Consumer(queues=self.queues,
                         callbacks=[self.on_message])]

    def on_message(self, body, message):
        jobs.init_index()
        job = body["job"]
        event = body["event"]
        print("Handle job event %s: job_id %s" % (event, job["id"]), flush=True)
        push(job, update=True)
        message.ack()


if __name__ == '__main__':

    session_db = dci_db.get_session_db()
   
    exchange = Exchange("dci-analytics-exchange", type="direct")
    queues = [Queue("dci-analytics-queue", exchange, routing_key="dci-analytics-jobs")]

    with Connection(rabbit_url, heartbeat=4) as conn:
            worker = Worker(conn, queues, session_db)
            worker.run()
